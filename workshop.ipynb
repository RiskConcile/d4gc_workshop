{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b61c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some generic imports that will be used throughout the workshop\n",
    "import datetime as dt\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7db2a00",
   "metadata": {},
   "source": [
    "## 1. Overview ‚Äî APIs and Web Scraping\n",
    "\n",
    "As humans, we interact with websites by **clicking, scrolling, and typing**.\n",
    "Computers, however, can‚Äôt ‚Äúsee‚Äù buttons or menus ‚Äî they need **structured ways to talk** to the web.\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/user_vs_api.png\" alt=\"user_vs_api\" width=\"200\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "There are two main approaches:\n",
    "\n",
    "1. **APIs**, which are the official, structured conversations.\n",
    "2. **Web Scraping**, where our program imitates a user and reads information directly from web pages.\n",
    "\n",
    "APIs are like **asking a waiter for a dish** ‚Äî you make a polite request and get exactly what you ordered.\n",
    "Scraping is more like **sneaking into the kitchen** to see what‚Äôs cooking.\n",
    "\n",
    "Both are useful, but APIs are preferred when available: they‚Äôre cleaner, faster, and far less likely to break when a website changes.\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/api_vs_scraper.png\" alt=\"api_vs_scraper\" width=\"200\"/>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2988da9",
   "metadata": {},
   "source": [
    "## 2. API Calls\n",
    "\n",
    "APIs (Application Programming Interfaces) are **the backbone of modern applications**.\n",
    "Every time you open Spotify, check Google Maps, or order an Uber, your device is making dozens of API calls behind the scenes ‚Äî quietly fetching playlists, traffic data, or driver locations.\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/api_on_web.png\" alt=\"api_on_web\" width=\"200\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "### How REST APIs Work\n",
    "\n",
    "Most web APIs today follow the **REST** design:\n",
    "\n",
    "* They use standard web methods ‚Äî **GET**, **POST**, **PUT**, **DELETE** ‚Äî to read, create, update, or remove data.\n",
    "* Each resource (for example, ‚Äústations‚Äù or ‚Äúdepartures‚Äù) has its own **URL**.\n",
    "* Requests and responses are structured in **JSON**.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "GET https://api.irail.be/liveboard/?station=Leuven&format=json\n",
    "```\n",
    "\n",
    "This returns real-time train departures from Leuven Station.\n",
    "\n",
    "**Why this matters:**\n",
    "As data scientists, APIs give us **direct, structured access to live data**, without relying on messy or unstable web scraping. They‚Äôre the ‚Äúprofessional‚Äù way for machines to communicate.\n",
    "\n",
    "### üöÄ **Let‚Äôs Code**\n",
    "We‚Äôll make our first API call using the iRail public API ‚Äî Belgium‚Äôs open train data ‚Äî and visualize how data travels from the web into our Python program.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732f62bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR API CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c737df",
   "metadata": {},
   "source": [
    "## 3. Web Scraping\n",
    "\n",
    "Not every website offers an API.\n",
    "Sometimes, the only way to access information is to **read what‚Äôs already visible** on the page ‚Äî just like a human would.\n",
    "That‚Äôs where **web scraping** comes in.\n",
    "\n",
    "Scraping isn‚Äôt hacking ‚Äî it‚Äôs **automated browsing** within fair-use limits.\n",
    "Our code acts as a mini-browser: it opens pages, looks for patterns in the HTML, and extracts the data we need.\n",
    "\n",
    "### Static vs Dynamic Pages\n",
    "\n",
    "* **Static pages**: all text is already in the HTML. ‚Üí Tools like `BeautifulSoup` work perfectly.\n",
    "* **Dynamic pages**: content loads via JavaScript after the page opens. ‚Üí We need **Selenium** to simulate a real browser.\n",
    "\n",
    "### Meet Selenium\n",
    "\n",
    "Selenium lets Python **control a browser** ‚Äî open pages, click buttons, fill forms, and extract text once the data has loaded.\n",
    "It‚Äôs also widely used in automated website testing.\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/selenium_workflow.png\" alt=\"selenium_workflow\" width=\"200\"/>\n",
    "</p>\n",
    "\n",
    "\n",
    "Typical steps:\n",
    "\n",
    "1. Launch a browser (`webdriver.Chrome()`).\n",
    "2. Open a URL (`.get(url)`).\n",
    "3. Wait for elements to load (`WebDriverWait`).\n",
    "4. Extract text (`find_element`, `find_elements`).\n",
    "5. Close the browser (`.quit()`).\n",
    "\n",
    "### üöÄ **Let‚Äôs Code**\n",
    "We‚Äôll use Selenium to open a web page, wait for the content to appear, and extract specific information ‚Äî just like a robot performing your browser actions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97783723",
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR SCRAPER CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43477a27",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Automatic File Observability\n",
    "\n",
    "As data scientists, we often receive new data files ‚Äî daily reports, exports, or client uploads ‚Äî that we need to process again and again.\n",
    "Instead of manually running a script each time, we can make our computer **watch a folder and react automatically** when new files appear.\n",
    "That‚Äôs the idea behind *automatic file observability*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e0da1",
   "metadata": {},
   "source": [
    "### Why would we want this?\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/pipeline.avif\" alt=\"pipeline\" width=\"150\"/>\n",
    "</p>\n",
    "\n",
    "File observability lets us:\n",
    "\n",
    "* **Automate repetitive ingestion tasks** (no more ‚Äúrerun the notebook‚Äù).\n",
    "* **React in real time** to new data.\n",
    "* Build the foundation for **event-driven data pipelines**, where workflows trigger on data arrival instead of on a timer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe2486",
   "metadata": {},
   "source": [
    "### How can we do this?\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/watchdog.png\" alt=\"watchdog\" width=\"250\"/>\n",
    "</p>\n",
    "\n",
    "The [`watchdog`](https://python-watchdog.readthedocs.io/) library lets Python scripts:\n",
    "\n",
    "1. **Monitor a directory** for file system events (new, changed, deleted files).\n",
    "2. **Define custom handlers** for what should happen when those events occur.\n",
    "3. **Run an observer** that keeps listening in the background.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19eef97",
   "metadata": {},
   "source": [
    "### Example: Build Your Own Invoice Bot\n",
    "\n",
    "<p align=\"left\">\n",
    "    <img src=\"data/assets/invoice.webp\" alt=\"invoice\" width=\"250\"/>\n",
    "</p>\n",
    "\n",
    "We‚Äôll use Watchdog to build a small **Invoice Bot** that:\n",
    "\n",
    "1. Watches an `invoices/` folder for new PDF invoices.\n",
    "2. Waits until each new file is ready.\n",
    "3. Uses a helper (`extract_invoice_data()`) to read key info and appends it to an Excel overview.\n",
    "\n",
    "Our focus here is the **watching and reacting** part ‚Äî the automation logic ‚Äî not the invoice parsing itself (that code lives in `utils/`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c04bd99",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### üöÄ Let‚Äôs Code!\n",
    "\n",
    "Let‚Äôs now implement our watcher step by step and see how our script can ‚Äúnotice‚Äù new invoices the moment they appear üëá\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261a123",
   "metadata": {},
   "outputs": [],
   "source": [
    "### We will use watchdog to monitor the directory for new files\n",
    "from watchdog.events import FileSystemEventHandler, FileCreatedEvent\n",
    "from watchdog.observers import Observer\n",
    "\n",
    "### We will use custom utility functions to extract invoice data from pdfs and handle\n",
    "### different file operations. Since they are not the key focus of this workshop, we\n",
    "### will not go into their implementation details. But if you are curious, feel free\n",
    "### to check out the code in the utils/ directory.\n",
    "from utils.invoice_data_extractor import extract_invoice_data\n",
    "from utils.file_handling import append_data_to_excel_file, wait_until_file_is_ready\n",
    "\n",
    "### Let's define the directory to watch and the file path to the invoice data excel \n",
    "### overview.\n",
    "WATCHED_DIR = Path(\"invoices\")\n",
    "INVOICE_DATA_FILE_PATH = WATCHED_DIR / \"invoice_data.xlsx\"\n",
    "\n",
    "### Watchdog lets us define custom functionality for different file system events. File\n",
    "### system events include file creation, modification, deletion, and movement. Here, we\n",
    "### will define a custom event handler that reacts to new file creation events.\n",
    "class InvoiceFileHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if not isinstance(event, FileCreatedEvent):\n",
    "            return\n",
    "        \n",
    "        p = Path(event.src_path)\n",
    "        \n",
    "        if p.suffix.lower() == \".pdf\":\n",
    "            wait_until_file_is_ready(p)\n",
    "            print(f\"New invoice detected: {p.name}\")\n",
    "            extracted_data = extract_invoice_data(p)\n",
    "            append_data_to_excel_file(extracted_data, INVOICE_DATA_FILE_PATH)\n",
    "\n",
    "### Let's define a function to start watching the directory for new files, and act \n",
    "### when the defined file system events occur. We will therefore have to use the \n",
    "### custom event handler we defined above, as well as watchdog's own observer.\n",
    "def start_watching():\n",
    "    WATCHED_DIR.mkdir(exist_ok=True)\n",
    "    observer = Observer()\n",
    "    observer.schedule(InvoiceFileHandler(), WATCHED_DIR, recursive=False)\n",
    "    observer.start()\n",
    "    print(f\"Watching directory: {WATCHED_DIR}\")\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "\n",
    "### Finally, let's start the file watching process and see it in action.\n",
    "start_watching()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
